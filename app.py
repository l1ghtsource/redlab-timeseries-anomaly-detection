# –ù–ï –ò–°–ü–û–õ–¨–ó–£–ï–¢–°–Ø, –¢–ï–ö–£–©–ê–Ø –í–ï–†–°–ò–Ø –≤ src/streamlit !!!

import clickhouse_connect
import streamlit as st
import pandas as pd
import altair as alt
import plotly.express as px
import plotly.graph_objects as go
import zipfile
import io
import re
from plotly.subplots import make_subplots

from ml.autoencoder import AnomaliesAER
from ml.isolation_forest import IsolationForestDetector
from ml.utils import TimeSeriesStatsCalculator
from ml.prophet_detector import ProphetDetector


def download_csv(df):
    csv = df.to_csv(index=False)
    return csv


def download_zip(data):
    zip_buffer = io.BytesIO()

    dataframes = [x[0] for x in data]
    names = [x[1] for x in data]

    with zipfile.ZipFile(zip_buffer, 'a', zipfile.ZIP_DEFLATED, False) as zip_file:
        for index, df in enumerate(dataframes):
            csv_buffer = io.StringIO()
            df.to_csv(csv_buffer, index=False)
            csv_buffer.seek(0)
            zip_file.writestr(f'{names[index]}_anomalies.csv', csv_buffer.read())

    zip_buffer.seek(0)
    return zip_buffer.getvalue()


def validate_time_format(time_str):
    pattern = re.compile(r'^\d{2}:\d{2}$')
    if pattern.match(time_str):
        hours, minutes = map(int, time_str.split(':'))
        if 0 <= hours < 24 and 0 <= minutes < 60:
            return True
    return False


st.set_page_config(
    page_title='–ü–æ–∏—Å–∫ –ê–Ω–æ–º–∞–ª–∏–π –≤–æ –í—Ä–µ–º–µ–Ω–Ω—ã—Ö –†—è–¥–∞—Ö',
    page_icon='üìâ',
    layout='wide',
    initial_sidebar_state='expanded'
)

alt.themes.enable('dark')


@st.cache_data
def find_anomalies_AER(timeseries):
    aer = AnomaliesAER(timeseries)
    anomalies = pd.DataFrame(aer.detect_anomalies())

    return anomalies


@st.cache_data
def find_anomalies_iforest(timeseries):
    detector = IsolationForestDetector()
    detector.fit(timeseries)

    return detector.df


@st.cache_data
def find_anomalies_prophet(timeseries):
    detector = ProphetDetector()
    anomalies = detector.fit_predict(timeseries)

    return anomalies


@st.cache_data
def get_info(timeseries, anomaly_df):
    stats_calculator = TimeSeriesStatsCalculator(timeseries)

    range_of_series = stats_calculator.get_range()
    mean_val = stats_calculator.get_mean()
    std_val = stats_calculator.get_std()

    anomalies_count = len(anomaly_df)

    return anomalies_count, range_of_series, mean_val, std_val


def find_anomalies(method, timeseries, start, end):
    if method == 'Autoencoder':
        anomalies = find_anomalies_AER(timeseries)

        timeseries['timestamp'] = pd.to_datetime(timeseries['timestamp'])
        anomalies['start'] = pd.to_datetime(anomalies['start'], unit='s')
        anomalies['end'] = pd.to_datetime(anomalies['end'], unit='s')

        timeseries = timeseries[(timeseries['timestamp'] >= start) & (timeseries['timestamp'] <= end)]
        anomalies = anomalies[(anomalies['start'] >= start) & (anomalies['end'] <= end)]

        fig = go.Figure()

        fig.add_trace(go.Scatter(x=timeseries['timestamp'],
                                 y=timeseries['value'],
                                 mode='lines',
                                 name='Time Series'))

        for _, row in anomalies.iterrows():
            anomaly_range = timeseries[(timeseries['timestamp'] >= row['start'])
                                       & (timeseries['timestamp'] <= row['end'])]
            fig.add_trace(go.Scatter(x=anomaly_range['timestamp'],
                                     y=anomaly_range['value'],
                                     mode='lines',
                                     line=dict(color='red')))

        fig.update_layout(xaxis_title='Time',
                          yaxis_title='Value',
                          title='Anomalies in Time Series [AER]')

        st.plotly_chart(fig)

        return anomalies

    elif method == 'Isolation Forest':
        df = find_anomalies_iforest(timeseries)
        df = df[(pd.to_datetime(df['timestamp']) >= start) & (pd.to_datetime(df['timestamp']) <= end)]
        anomalies_df = df[df['anomaly'] == -1].drop(columns='anomaly').reset_index().drop(columns='index')

        timeseries['timestamp'] = pd.to_datetime(timeseries['timestamp'])

        fig = go.Figure()

        fig.add_trace(go.Scatter(
            x=df.index, y=df['value'], mode='lines', name='Value'))

        anomaly_dates = df[df['anomaly'] == -1].index
        fig.add_trace(go.Scatter(x=anomaly_dates, y=df.loc[anomaly_dates]['value'],
                                 mode='markers', marker=dict(color='red'), name='Anomalies'))

        fig.update_layout(title=f'Anomalies in Time Series [Isolation Forest]',
                          xaxis_title='Datetime',
                          yaxis_title='Value')

        st.plotly_chart(fig)

        return anomalies_df

    elif method == 'Prophet':
        anomalies_df = find_anomalies_prophet(timeseries)

        anomalies_df = anomalies_df[(pd.to_datetime(anomalies_df['timestamp']) >= start)
                                    & (pd.to_datetime(anomalies_df['timestamp']) <= end)]

        timeseries = timeseries[(timeseries['timestamp'] >= start) & (timeseries['timestamp'] <= end)]

        fig = go.Figure()

        fig.add_trace(go.Scatter(x=timeseries['timestamp'], y=timeseries['value'], mode='lines', name='Value'))

        anomaly_dates = anomalies_df['timestamp']

        fig.add_trace(
            go.Scatter(
                x=anomaly_dates, y=anomalies_df.loc[anomalies_df['timestamp'] == anomaly_dates]['value'],
                mode='markers', marker=dict(color='red'),
                name='Anomalies'))

        fig.update_layout(title='Anomalies in Time Series [Prophet]',
                          xaxis_title='Datetime',
                          yaxis_title='Value')

        st.plotly_chart(fig)

        return anomalies_df

    elif method == 'Multidimensional':
        fig = make_subplots(rows=len(timeseries.columns) - 1, cols=1, shared_xaxes=True,
                            subplot_titles=[f"Anomalies in {column}"
                                            for column in timeseries.columns[1:]])
        results = []

        for i, column in enumerate(timeseries.columns[1:]):
            ts = timeseries[['timestamp', column]]
            ts.rename(columns={column: 'value'}, inplace=True)

            df = find_anomalies_iforest(ts)

            df = df[(pd.to_datetime(df['timestamp']) >= start) & (pd.to_datetime(df['timestamp']) <= end)]

            anomalies_df = df[df['anomaly'] == -1].drop(columns='anomaly').reset_index().drop(columns='index')

            fig.add_trace(go.Scatter(x=df.index, y=df['value'], mode='lines', name='Value'), row=i+1, col=1)

            anomaly_dates = df[df['anomaly'] == -1].index
            fig.add_trace(
                go.Scatter(
                    x=anomaly_dates, y=df.loc[anomaly_dates]['value'],
                    mode='markers', marker=dict(color='red'),
                    name='Anomalies'),
                row=i + 1, col=1)

            results.append([anomalies_df, column])

        fig.update_layout(height=200*len(timeseries.columns),
                          title_text="Anomalies in Multidimensional Time Series [Isolation Forest]",
                          xaxis_title='Time',
                          showlegend=False)

        st.plotly_chart(fig, use_container_width=True)

        return results


def main():
    state = st.session_state.get("state", "initial")

    if state == "initial":
        st.title('üìâ –ü–æ–∏—Å–∫ –ê–Ω–æ–º–∞–ª–∏–π –≤–æ –í—Ä–µ–º–µ–Ω–Ω—ã—Ö –†—è–¥–∞—Ö')

        uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª", type=['csv'])
        if uploaded_file is not None:
            st.session_state["data"] = pd.read_csv(uploaded_file)
            st.session_state["state"] = "working"
            st.session_state["start"] = pd.to_datetime(st.session_state["data"]['timestamp'].min())
            st.session_state["end"] = pd.to_datetime(st.session_state["data"]['timestamp'].max())
            st.rerun()

        if st.button("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–≥–∏ –∏–∑ –ë–î"):
            client = clickhouse_connect.get_client(host='83.166.235.106', port=8123)
            result = client.query_df(
                'SELECT timestamp, web_response, throughput, apdex, error FROM "default"."test2" ORDER BY timestamp ASC')
            # result.rename(columns={'time': 'timestamp'}, inplace=True)

            st.session_state["data"] = result
            st.session_state["state"] = "working"
            st.session_state["start"] = pd.to_datetime(st.session_state["data"]['timestamp'].min())
            st.session_state["end"] = pd.to_datetime(st.session_state["data"]['timestamp'].max())
            st.rerun()

    elif state == "working":
        timeseries_all = st.session_state["data"]

        with st.sidebar:
            st.title('üìâ –ü–æ–∏—Å–∫ –ê–Ω–æ–º–∞–ª–∏–π –≤–æ –í—Ä–µ–º–µ–Ω–Ω—ã—Ö –†—è–¥–∞—Ö')

            methods_list = [
                'Isolation Forest',
                'Prophet',
                'Autoencoder',
                'Multidimensional'
            ]

            numeric_columns = timeseries_all.select_dtypes(include=['float', 'int'])
            numeric_column_names = numeric_columns.columns.tolist()

            selected_method = st.selectbox('–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π', methods_list)

            if selected_method != 'Multidimensional':
                selected_value = st.selectbox('–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π', numeric_column_names)
                timeseries = pd.concat([timeseries_all['timestamp'], timeseries_all[selected_value]], axis=1)
                timeseries.rename(columns={selected_value: 'value'}, inplace=True)
            else:
                timeseries = timeseries_all

            if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª"):
                st.session_state["state"] = "initial"
                st.rerun()

            elif st.button("–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞"):
                st.session_state["state"] = "analyse"
                st.rerun()

            # with st.expander('–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Ä–µ–∂–∏–º–∞—Ö', expanded=True):
            #     st.write('''
            #         - –¢–µ–∫—Å—Ç.
            #         - :orange[**–ï—â–µ —Ç–µ–∫—Å—Ç**]: –ø—Ä–æ —á—Ç–æ-—Ç–æ
            #         - :orange[**–ò –µ—â–µ —Ç–µ–∫—Å—Ç**]: –±—Ä–µ–¥–æ–≤—ã–π
            #         ''')

        if selected_method != 'Multidimensional':
            col = st.columns((1.5, 4.5, 2), gap='medium')

            anomaly_df = pd.DataFrame()

            with col[1]:
                st.markdown('#### –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏')
                start_datetime = st.session_state["start"]
                end_datetime = st.session_state["end"]
                anomaly_df = find_anomalies(selected_method, timeseries, start_datetime, end_datetime)

            with col[2]:
                st.markdown('#### –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã')
                st.dataframe(anomaly_df, width=500)

            with col[0]:
                st.markdown('#### –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è')

                anomalies_count, range_of_series, mean_val, std_val = get_info(timeseries, anomaly_df)

                st.metric(label=':white[–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–æ–º–∞–ª–∏–π]',
                          value=anomalies_count)

                st.metric(label=':white[–†–∞–∑–º–∞—Ö]',
                          value=round(range_of_series, 4))

                st.metric(label=':white[–°—Ä–µ–¥–Ω–µ–µ]',
                          value=round(mean_val, 4))

                st.metric(label=':white[–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ]',
                          value=round(std_val, 4))

                st.markdown('#### –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç')

                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å CSV",
                    data=download_csv(anomaly_df),
                    file_name=f'anomalies_{selected_method}.csv',
                    mime='text/csv'
                )

            min_date = pd.to_datetime(timeseries_all['timestamp'].min())
            max_date = pd.to_datetime(timeseries_all['timestamp'].max())

            start_date = st.date_input('–í—ã–±–µ—Ä–∏—Ç–µ –Ω–∞—á–∞–ª—å–Ω—É—é –¥–∞—Ç—É', min_value=min_date,
                                       max_value=max_date, value=min_date)
            time_input_start = st.text_input('–í–≤–µ–¥–∏—Ç–µ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ hh mm', value='00:00')

            end_date = st.date_input('–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–Ω–µ—á–Ω—É—é –¥–∞—Ç—É', min_value=min_date, max_value=max_date, value=max_date)
            time_input_end = st.text_input('–í–≤–µ–¥–∏—Ç–µ –≤—Ä–µ–º—è –∫–æ–Ω—Ü–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ hh mm', value='00:00')

            if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä"):
                if validate_time_format(time_input_start) and validate_time_format(time_input_end):
                    start_datetime = pd.to_datetime(str(start_date).split()[0] + ' ' + time_input_start)
                    end_datetime = pd.to_datetime(str(end_date).split()[0] + ' ' + time_input_end)

                    st.session_state["state"] = "working"
                    st.session_state["start"] = start_datetime
                    st.session_state["end"] = end_datetime
                    st.rerun()
                else:
                    st.error(f'–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ä–µ–º–µ–Ω–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ hh mm (—á–µ—Ä–µ–∑ –¥–≤–æ–µ—Ç–æ—á–∏–µ)')

        else:
            start_datetime = st.session_state["start"]
            end_datetime = st.session_state["end"]
            results = find_anomalies('Multidimensional', timeseries_all, start_datetime, end_datetime)

            min_date = pd.to_datetime(timeseries_all['timestamp'].min())
            max_date = pd.to_datetime(timeseries_all['timestamp'].max())

            start_date = st.date_input('–í—ã–±–µ—Ä–∏—Ç–µ –Ω–∞—á–∞–ª—å–Ω—É—é –¥–∞—Ç—É', min_value=min_date,
                                       max_value=max_date, value=min_date)
            time_input_start = st.text_input('–í–≤–µ–¥–∏—Ç–µ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ hh mm', value='00:00')

            end_date = st.date_input('–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–Ω–µ—á–Ω—É—é –¥–∞—Ç—É', min_value=min_date, max_value=max_date, value=max_date)
            time_input_end = st.text_input('–í–≤–µ–¥–∏—Ç–µ –≤—Ä–µ–º—è –∫–æ–Ω—Ü–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ hh mm', value='00:00')

            if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä"):
                if validate_time_format(time_input_start) and validate_time_format(time_input_end):
                    start_datetime = pd.to_datetime(str(start_date).split()[0] + ' ' + time_input_start)
                    end_datetime = pd.to_datetime(str(end_date).split()[0] + ' ' + time_input_end)

                    st.session_state["state"] = "working"
                    st.session_state["start"] = start_datetime
                    st.session_state["end"] = end_datetime
                    st.rerun()
                else:
                    st.error(f'–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ä–µ–º–µ–Ω–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ hh mm')

            st.download_button(
                label="–°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç—ã CSV",
                data=download_zip(results),
                file_name=f'anomalies_{selected_method}.zip'
            )

    elif state == "analyse":
        timeseries_all = st.session_state["data"]

        with st.sidebar:
            st.title('üìâ –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞')

            methods_list = [
                '–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä–µ–ª–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã',
                '–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π'
            ]

            selected_method = st.selectbox('–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã', methods_list)

            if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª"):
                st.session_state["state"] = "initial"
                st.rerun()

            elif st.button("–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –ø–æ–∏—Å–∫—É –∞–Ω–æ–º–∞–ª–∏–π"):
                st.session_state["state"] = "working"
                st.rerun()

            # with st.expander('–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Ä–µ–∂–∏–º–∞—Ö', expanded=True):
            #     st.write('''
            #         - –¢–µ–∫—Å—Ç.
            #         - :orange[**–ï—â–µ —Ç–µ–∫—Å—Ç**]: –ø—Ä–æ —á—Ç–æ-—Ç–æ
            #         - :orange[**–ò –µ—â–µ —Ç–µ–∫—Å—Ç**]: –±—Ä–µ–¥–æ–≤—ã–π
            #         ''')

        if selected_method == '–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä–µ–ª–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã':
            stats_calculator = TimeSeriesStatsCalculator(timeseries_all)
            corr_matrix = stats_calculator.get_correlation().round(2)

            fig = px.imshow(corr_matrix, text_auto=True, aspect="auto", color_continuous_scale="blugrn")
            fig.update_layout(title='–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä–µ–ª–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã')

            st.plotly_chart(fig)

            corr_pairs = corr_matrix > 0.9

            pairs = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    if corr_pairs.iloc[i, j]:
                        pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))

            res = '–ü–∞—Ä—ã —Å –∫–æ—Ä–µ–ª–ª—è—Ü–∏–µ–π > 0.9: '

            for pair in pairs:
                res += f'{pair[0]} –∏ {pair[1]} ({pair[2]})'

            st.write(res)

        elif selected_method == '–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π':
            pass


if __name__ == "__main__":
    main()
